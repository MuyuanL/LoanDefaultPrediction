
all data scale to (0,1)
read the first 1000 row

a. SVR  k=5 final loss test,train)
rbf:
regressor = SVR(kernel = 'rbf',gamma='scale',C=1)
final loss 19.352155237737033 74.18781492460997
final loss 30.56998495841975 70.33147897555735
final loss 51.9573512252556 56.402036372780564
final loss 36.52497770433613 67.41593095279991
final loss 23.379462110470822 73.0072191530531

regressor = SVR(kernel = 'rbf',gamma='scale',C=10)
final loss 19.408778652508904 73.90436732417172
final loss 30.655342111938662 70.04328800415274
final loss 52.01442107723588 56.071646758462244
final loss 36.60205081351396 67.10962934736212
final loss 23.06509083526024 72.7350396640142

regressor = SVR(kernel = 'rbf',gamma='scale',C=100)
final loss 19.08012874826447 72.09903406725896
final loss 30.23379779366773 68.19971813537042
final loss 51.73326613882583 54.134143098254256
final loss 36.25491696285351 65.1819599023944
final loss 23.09564355941413 71.11201455209768

linear:
 C=1
final loss 8.706934183835186e+38 73.92091939019235
final loss 30.655342111938662 70.0440844208871
final loss 3.376444830695914e+40 56.144610207256086
final loss 36.62308015445998 67.04614739351275
final loss 9.440258866271334e+39 72.74256566239141

C=10
final loss 19.480759738778158 73.58388773547259
final loss 30.655342111938662 69.64529046757076
final loss 4.0090728931767223e+40 55.85611628782671
final loss 36.62308015445998 66.70777657966322
final loss 23.569047498785352 72.41949762261511

b. gradient decent:(final loss train [test]
linear regression
final loss 32.8071033687924  1.0646704189045504e+43
final loss 29.22463884951982  8.919488216384795e+43
final loss 30.556917884449007  4.782899586941189e+43
final loss 27.782774797835238  2.6605339792190344e+44
final loss 37.09295951528034  2.533460570049789e+44